---
title:  "'Dave...I can asure you...that it's going to be all right' -- A definition, case for, and survey of algorithmic assurances in human-autonomy trust relationships"
date:   2018-08-13 08:00:00
comments: false
category: pubs
tags: [AI, Trust, ML, Assurances, AIA]
---
#### Notes:
This paper was just accepted to the ACM Computing Surveys (ACM CSUR) Journal today!! I'm really excited, and grateful to my co-author, and adviser, Dr. Nisar Ahmed. We put a lot of work into this document, and hope it will be useful to others.

This is an evolution of the (much less refined) document that I wrote for my prelim exam (which, unfortunately, has a very similar name). This document has been ***greatly improved***, thanks to feedback from Eric Frew, and Mike Mozer (my committee members), as well as comments from reviewers for the CSUR journal. I am very happy with the final product.

> **Abstract**: Those who design, use, and are otherwise affected by advanced, technologies like artificially intelligent, autonomous systems want to know that these systems will perform correctly, understand the reasons behind their actions, and know how to use them appropriately. In short: they want to be able to trust such systems. Consequently, designers have devised various kinds of assurances for assessing trust. Typically, however, these assessments are ad hoc, and have not been formally related to each other or to formal trust models. This paper presents a survey of algorithmic assurances that allow users to calibrate their trust in autonomous artificially intelligent agents and use such autonomous agents more appropriately. To this end algorithmic assurances are first formally defined, and classified, from the perspective of formally modeled trust relationships. The survey is then performed using research from related communities such as machine learning, human-computer interaction, human-robot interaction, e-commerce, and others. The literature for different classes of assurances are identified with seven different levels of integration for artificially intelligent agents; these classes are useful for practitioners and system designers. Recommendations and directions for future work are also presented.

#### PDF Link(s): [pre-print][arxiv]

#### BibTeX:
``` TeX

@ARTICLE{Israelsen2017-ym,
  title         = "``{Dave...I} can assure you...that it's going to be all
                   right...'' -- A definition, case for, and survey of
                   algorithmic assurances in human-autonomy trust relationships",
  author        = "Israelsen, Brett W and Ahmed, Nisar R",
  abstract      = "Those who design, use, and are otherwise affected by
                   advanced, technologies like artificially intelligent,
                   autonomous systems want to know that these systems will
                   perform correctly, understand the reasons behind their
                   actions, and know how to use them appropriately. In short:
                   they want to be able to trust such systems. Consequently,
                   designers have devised various kinds of assurances for
                   assessing trust. Typically, however, these assessments are
                   ad hoc, and have not been formally related to each other or
                   to formal trust models. This paper presents a survey of
                   algorithmic assurances that allow users to calibrate their
                   trust in autonomous artificially intelligent agents and use
                   such autonomous agents more appropriately. To this end
                   algorithmic assurances are first formally defined, and
                   classified, from the perspective of formally modeled trust
                   relationships. The survey is then performed using research
                   from related communities such as machine learning,
                   human-computer interaction, human-robot interaction,
                   e-commerce, and others. The literature for different classes
                   of assurances are identified with seven different levels of
                   integration for artificially intelligent agents; these
                   classes are useful for practitioners and system designers.
                   Recommendations and directions for future work are also
                   presented.",
  month         =  nov,
  year          =  2017,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CY",
  eprint        = "1711.03846"
}

```

[arxiv]:       https://goo.gl/UV8wP2
